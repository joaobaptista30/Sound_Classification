{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepFool Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CÃ¡lculo dos Gradientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "\n",
    "def get_gradients(model, x): # get gradients for all the classes at the same time (with respect to the input)\n",
    "\n",
    "    with tf.GradientTape() as gtape:\n",
    "        inputs = [tf.cast(input_value, dtype = tf.float64) for input_value in x]\n",
    "        for input_value in inputs:\n",
    "            gtape.watch(input_value)\n",
    "        results = model(inputs)\n",
    "\n",
    "    gradients = gtape.gradient(results, inputs)\n",
    "    del tape\n",
    "    return [grad.numpy() for grad in gradients], results.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deepfool(model, x0, eta=0.02, max_iter=20, epsilon=1e-6):\n",
    "    \"\"\"\n",
    "    Improved DeepFool algorithm with gradient optimization, stopping criteria, and dynamic overshoot.\n",
    "    \"\"\"\n",
    "    # Initial label and model output\n",
    "    f_x0 = model(x0).numpy().flatten()\n",
    "    label_x0 = np.argmax(f_x0)\n",
    "    \n",
    "    xi = deepcopy(x0)\n",
    "    label_xi = label_x0\n",
    "    loop_i = 0\n",
    "    perturbations = []\n",
    "\n",
    "    while label_xi == label_x0 and loop_i < max_iter:\n",
    "        grad_f_xi, f_xi = get_gradients(model, xi)  # Gradients and logits for xi\n",
    "        grad_f_label_x0 = [g[label_x0] for g in grad_f_xi]  # Gradient for true class\n",
    "        \n",
    "        min_fk_wk = np.inf  # Initialize minimum distance to decision boundary\n",
    "        w_l, f_l = None, None\n",
    "\n",
    "        # Loop through other classes\n",
    "        for k in range(f_xi.shape[1]):  # Iterate over all classes\n",
    "            if k == label_x0:\n",
    "                continue\n",
    "            grad_f_k = [g[k] for g in grad_f_xi]  # Gradient for class k\n",
    "            w_k = [g_k - g_label for g_k, g_label in zip(grad_f_k, grad_f_label_x0)]  # Direction\n",
    "            w_k_norm = np.sqrt(np.sum([np.linalg.norm(w)**2 for w in w_k]))\n",
    "            f_k = f_xi[0, k] - f_xi[0, label_x0]  # Difference in logits\n",
    "            fk_wk = abs(f_k) / (w_k_norm + epsilon)  # Distance to boundary\n",
    "\n",
    "            if fk_wk < min_fk_wk:\n",
    "                min_fk_wk = fk_wk\n",
    "                w_l, f_l = w_k, f_k\n",
    "\n",
    "        # Compute perturbation step\n",
    "        w_l_squared_norm = np.sum([np.linalg.norm(w)**2 for w in w_l])\n",
    "        ri_const = abs(f_l) / (w_l_squared_norm + epsilon)\n",
    "        ri = [ri_const * w for w in w_l]  # Perturbation\n",
    "        perturbations.append(ri)\n",
    "\n",
    "        # Update perturbed input\n",
    "        xi = [xi_item + (1 + eta) * ri_item for xi_item, ri_item in zip(xi, ri)]\n",
    "        xi = [tf.clip_by_value(xi_item, 0, 1).numpy() for xi_item in xi]  # Ensure input bounds [0,1]\n",
    "        \n",
    "        # Update label and loop count\n",
    "        label_xi = np.argmax(model(xi).numpy().flatten())\n",
    "        loop_i += 1\n",
    "\n",
    "        # Stopping criteria: small perturbation\n",
    "        if np.sqrt(np.sum([np.linalg.norm(r)**2 for r in ri])) < epsilon:\n",
    "            break\n",
    "\n",
    "    # Summing up all perturbations\n",
    "    total_perturbation = [np.sum([r[i] for r in perturbations], axis=0) for i in range(len(x0))]\n",
    "\n",
    "    return total_perturbation, loop_i, label_xi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_robustness(x, r):\n",
    "    \"\"\"\n",
    "    Calculate robustness measure for an individual example.\n",
    "    \"\"\"\n",
    "    r_norm = np.sqrt(np.sum([np.linalg.norm(r_input)**2 for r_input in r]))\n",
    "    x_norm = np.sqrt(np.sum([np.linalg.norm(x_input)**2 for x_input in x]))\n",
    "    return r_norm / x_norm\n",
    "\n",
    "\n",
    "def model_robustness(example_robustness_list):\n",
    "    \"\"\"\n",
    "    Calculate mean and standard deviation of robustness for the model.\n",
    "    \"\"\"\n",
    "    mean = np.mean(example_robustness_list)\n",
    "    std = np.std(example_robustness_list)\n",
    "    return mean, std"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
