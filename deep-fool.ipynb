{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepFool Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a given classifier and example, the algorithm is set to compute the minimal perturbation that is sufficient to change the estimated label. For the remainder of the section, the following notation will be used:\n",
    "\n",
    "- $f$: a given classifier that outputs a vector with the probability distribution for the classification associated with its probability index.\n",
    "\n",
    "- $x$: a given example.\n",
    "\n",
    "- $X$: the domain of the examples.\n",
    "\n",
    "- $T$: the domain of test examples available.\n",
    "\n",
    "- $k$: a possible classification of the considered problem. Thus, the probability of the classification of an example $x$ to be $k$ is $f_k(x)$.\n",
    "\n",
    "- $\\hat{k}(x)$: the estimated classification of a given example. It is noted that $\\hat{k}(x) = argmax_k( f_k(x) )$.\n",
    "\n",
    "- $\\hat{r}(x)$: the minimal perturbation for which $\\hat{k}(x) \\ne \\hat{k}(x+\\hat{r}(x))$.\n",
    "\n",
    "The DeepFool algorithm only outputs the value of the minimal perturbation $\\hat{r}(x)$ of a given example $x$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the proposed formal definition for the robustness to adversarial examples of a given classifier is the expected value over the domain of examples for the norm of the minimal perturbation for an example divided by the norm of that same example. For practical purposes, the aforementioned expected value is approximated to the mean value for all examples in the available test domain of the classifier:\n",
    "\n",
    "$\\rho_{adv}(f) = ùîº_X \\frac{||\\hat{r}(x)||_2}{||x||_2} ‚âà \\frac{1}{|T|} ‚àë_{x\\in T} \\frac{||\\hat{r}(x)||_2}{||x||_2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to calculate the gradients of all the classes at the same time (with respect to the input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "\n",
    "def get_gradients(model, x): # get gradients for all the classes at the same time (with respect to the input)\n",
    "\n",
    "    with tf.GradientTape() as gtape:\n",
    "        inputs = [tf.cast(input_value, dtype = tf.float64) for input_value in x]\n",
    "        for input_value in inputs:\n",
    "            gtape.watch(input_value)\n",
    "        results = model(inputs)\n",
    "\n",
    "    gradients = gtape.gradient(results, inputs)\n",
    "    del tape\n",
    "    return [grad.numpy() for grad in gradients], results.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deepfool(model, x0, eta=0.02, max_iter=20, epsilon=1e-6):\n",
    "    \"\"\"\n",
    "    Improved DeepFool algorithm with gradient optimization, stopping criteria, and dynamic overshoot.\n",
    "    \"\"\"\n",
    "    # Initial label and model output\n",
    "    f_x0 = model(x0).numpy().flatten()\n",
    "    label_x0 = np.argmax(f_x0)\n",
    "    \n",
    "    xi = deepcopy(x0)\n",
    "    label_xi = label_x0\n",
    "    loop_i = 0\n",
    "    perturbations = []\n",
    "\n",
    "    while label_xi == label_x0 and loop_i < max_iter:\n",
    "        grad_f_xi, f_xi = get_gradients(model, xi)  # Gradients and logits for xi\n",
    "        grad_f_label_x0 = [g[label_x0] for g in grad_f_xi]  # Gradient for true class\n",
    "        \n",
    "        min_fk_wk = np.inf  # Initialize minimum distance to decision boundary\n",
    "        w_l, f_l = None, None\n",
    "\n",
    "        # Loop through other classes\n",
    "        for k in range(f_xi.shape[1]):  # Iterate over all classes\n",
    "            if k == label_x0:\n",
    "                continue\n",
    "            grad_f_k = [g[k] for g in grad_f_xi]  # Gradient for class k\n",
    "            w_k = [g_k - g_label for g_k, g_label in zip(grad_f_k, grad_f_label_x0)]  # Direction\n",
    "            w_k_norm = np.sqrt(np.sum([np.linalg.norm(w)**2 for w in w_k]))\n",
    "            f_k = f_xi[0, k] - f_xi[0, label_x0]  # Difference in logits\n",
    "            fk_wk = abs(f_k) / (w_k_norm + epsilon)  # Distance to boundary\n",
    "\n",
    "            if fk_wk < min_fk_wk:\n",
    "                min_fk_wk = fk_wk\n",
    "                w_l, f_l = w_k, f_k\n",
    "\n",
    "        # Compute perturbation step\n",
    "        w_l_squared_norm = np.sum([np.linalg.norm(w)**2 for w in w_l])\n",
    "        ri_const = abs(f_l) / (w_l_squared_norm + epsilon)\n",
    "        ri = [ri_const * w for w in w_l]  # Perturbation\n",
    "        perturbations.append(ri)\n",
    "\n",
    "        # Update perturbed input\n",
    "        xi = [xi_item + (1 + eta) * ri_item for xi_item, ri_item in zip(xi, ri)]\n",
    "        xi = [tf.clip_by_value(xi_item, 0, 1).numpy() for xi_item in xi]  # Ensure input bounds [0,1]\n",
    "        \n",
    "        # Update label and loop count\n",
    "        label_xi = np.argmax(model(xi).numpy().flatten())\n",
    "        loop_i += 1\n",
    "\n",
    "        # Stopping criteria: small perturbation\n",
    "        if np.sqrt(np.sum([np.linalg.norm(r)**2 for r in ri])) < epsilon:\n",
    "            break\n",
    "\n",
    "    # Summing up all perturbations\n",
    "    total_perturbation = [np.sum([r[i] for r in perturbations], axis=0) for i in range(len(x0))]\n",
    "\n",
    "    return total_perturbation, loop_i, label_xi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_robustness(x, r):\n",
    "    \"\"\"\n",
    "    Calculate robustness measure for an individual example.\n",
    "    \"\"\"\n",
    "    r_norm = np.sqrt(np.sum([np.linalg.norm(r_input)**2 for r_input in r]))\n",
    "    x_norm = np.sqrt(np.sum([np.linalg.norm(x_input)**2 for x_input in x]))\n",
    "    return r_norm / x_norm\n",
    "\n",
    "\n",
    "def model_robustness(example_robustness_list):\n",
    "    \"\"\"\n",
    "    Calculate mean and standard deviation of robustness for the model.\n",
    "    \"\"\"\n",
    "    mean = np.mean(example_robustness_list)\n",
    "    std = np.std(example_robustness_list)\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- Moosavi-Dezfooli, S.-M., Fawzi, A., Frossard, P., Polytechnique, E. and De Lausanne, F. (2016). DeepFool: a simple and accurate method to fool deep neural networks: https://openaccess.thecvf.com/content_cvpr_2016/papers/Moosavi-Dezfooli_DeepFool_A_Simple_CVPR_2016_paper.pdf.\n",
    "\n",
    "- TensorFlow. (2023). Introduction to gradients and automatic differentiation | TensorFlow Core. [online] Available at: https://www.tensorflow.org/guide/autodiff."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
