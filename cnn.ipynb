{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "# Cnn classifier\n",
    "\n",
    "In this notebook, we implemented a Convolutional Neural Network (CNN) that processes images through convolutional and pooling layers. These layers reduce the original dimensionality of the data while increasing the number of features, thereby extracting meaningful patterns from the input. After this, the data is linearized, and the network is trained to hoppefuly produce a correct output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "All the necesssary imports in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T21:11:07.50238Z",
     "iopub.status.busy": "2022-02-19T21:11:07.501806Z",
     "iopub.status.idle": "2022-02-19T21:11:09.890749Z",
     "shell.execute_reply": "2022-02-19T21:11:09.889786Z",
     "shell.execute_reply.started": "2022-02-19T21:11:07.502291Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from glob import glob\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "\n",
    "from itertools import cycle\n",
    "\n",
    "sns.set_theme(style=\"white\", palette=None)\n",
    "color_pal = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n",
    "color_cycle = cycle(plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Terms to know for Audio in Digital Form:\n",
    "\n",
    "## Frequency (Hz)\n",
    "- Frequency describes the differences of wave lengths.\n",
    "- We interperate frequency has high and low pitches.\n",
    "\n",
    "<img src=\"https://uploads-cdn.omnicalculator.com/images/britannica-wave-frequency.jpg\" width=\"400\"/>\n",
    "\n",
    "## Intensity (db / power)\n",
    "- Intensity describes the amplitude (height) of the wave.\n",
    "\n",
    "<img src=\"https://ars.els-cdn.com/content/image/3-s2.0-B9780124722804500162-f13-15-9780124722804.gif\" width=\"400\"/>\n",
    "\n",
    "## Sample Rate\n",
    "- Sample rate is specific to how the computer reads in the audio file.\n",
    "- Think of it as the \"resolution\" of the audio.\n",
    "\n",
    "<img src=\"https://www.headphonesty.com/wp-content/uploads/2019/07/Sample-Rate-Bit-Depth-and-Bit-Rate.jpeg\" width=\"400\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading in Audio Files\n",
    "There are many types of audio files: `mp3`, `wav`, `m4a`, `flac`, `ogg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T21:17:05.56168Z",
     "iopub.status.busy": "2022-02-19T21:17:05.560814Z",
     "iopub.status.idle": "2022-02-19T21:17:05.592357Z",
     "shell.execute_reply": "2022-02-19T21:17:05.591717Z",
     "shell.execute_reply.started": "2022-02-19T21:17:05.561631Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "audio_files = glob('UrbanSound8K/audio/fold1/*.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T21:17:31.840115Z",
     "iopub.status.busy": "2022-02-19T21:17:31.83982Z",
     "iopub.status.idle": "2022-02-19T21:17:31.869235Z",
     "shell.execute_reply": "2022-02-19T21:17:31.868431Z",
     "shell.execute_reply.started": "2022-02-19T21:17:31.840083Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Play audio file\n",
    "ipd.Audio(audio_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T21:19:29.501743Z",
     "iopub.status.busy": "2022-02-19T21:19:29.501419Z",
     "iopub.status.idle": "2022-02-19T21:19:29.678071Z",
     "shell.execute_reply": "2022-02-19T21:19:29.677344Z",
     "shell.execute_reply.started": "2022-02-19T21:19:29.501714Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "y, sr = librosa.load(audio_files[0])\n",
    "print(f'y: {y[:10]}')\n",
    "print(f'shape y: {y.shape}')\n",
    "print(f'sr: {sr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T21:21:03.374852Z",
     "iopub.status.busy": "2022-02-19T21:21:03.374562Z",
     "iopub.status.idle": "2022-02-19T21:21:03.642317Z",
     "shell.execute_reply": "2022-02-19T21:21:03.641635Z",
     "shell.execute_reply.started": "2022-02-19T21:21:03.374821Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pd.Series(y).plot(figsize=(10, 5),\n",
    "                  lw=1,\n",
    "                  title='Raw Audio Example',\n",
    "                 color=color_pal[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T21:23:54.390065Z",
     "iopub.status.busy": "2022-02-19T21:23:54.389489Z",
     "iopub.status.idle": "2022-02-19T21:23:54.639935Z",
     "shell.execute_reply": "2022-02-19T21:23:54.63938Z",
     "shell.execute_reply.started": "2022-02-19T21:23:54.390029Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Trimming leading/lagging silence\n",
    "y_trimmed, _ = librosa.effects.trim(y, top_db=20)\n",
    "pd.Series(y_trimmed).plot(figsize=(10, 5),\n",
    "                  lw=1,\n",
    "                  title='Raw Audio Trimmed Example',\n",
    "                 color=color_pal[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T21:25:40.965344Z",
     "iopub.status.busy": "2022-02-19T21:25:40.965005Z",
     "iopub.status.idle": "2022-02-19T21:25:41.1966Z",
     "shell.execute_reply": "2022-02-19T21:25:41.195712Z",
     "shell.execute_reply.started": "2022-02-19T21:25:40.965307Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pd.Series(y[30000:30500]).plot(figsize=(10, 5),\n",
    "                  lw=1,\n",
    "                  title='Raw Audio Zoomed In Example',\n",
    "                 color=color_pal[2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T21:28:11.620901Z",
     "iopub.status.busy": "2022-02-19T21:28:11.620131Z",
     "iopub.status.idle": "2022-02-19T21:28:11.63607Z",
     "shell.execute_reply": "2022-02-19T21:28:11.635291Z",
     "shell.execute_reply.started": "2022-02-19T21:28:11.620858Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "D = librosa.stft(y)\n",
    "S_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)\n",
    "S_db.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T21:30:40.191221Z",
     "iopub.status.busy": "2022-02-19T21:30:40.190957Z",
     "iopub.status.idle": "2022-02-19T21:30:40.622933Z",
     "shell.execute_reply": "2022-02-19T21:30:40.622047Z",
     "shell.execute_reply.started": "2022-02-19T21:30:40.191193Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Plot the transformed audio data\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "img = librosa.display.specshow(S_db,\n",
    "                              x_axis='time',\n",
    "                              y_axis='log',\n",
    "                              ax=ax)\n",
    "ax.set_title('Spectogram Example', fontsize=20)\n",
    "fig.colorbar(img, ax=ax, format=f'%0.2f')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mel Spectogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T21:37:18.363461Z",
     "iopub.status.busy": "2022-02-19T21:37:18.363181Z",
     "iopub.status.idle": "2022-02-19T21:37:18.387745Z",
     "shell.execute_reply": "2022-02-19T21:37:18.38681Z",
     "shell.execute_reply.started": "2022-02-19T21:37:18.363427Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "S = librosa.feature.melspectrogram(y=y,\n",
    "                                   sr=sr,\n",
    "                                   n_mels=512,)\n",
    "S_db_mel = librosa.amplitude_to_db(S, ref=np.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-19T21:37:18.726563Z",
     "iopub.status.busy": "2022-02-19T21:37:18.726294Z",
     "iopub.status.idle": "2022-02-19T21:37:19.040674Z",
     "shell.execute_reply": "2022-02-19T21:37:19.039786Z",
     "shell.execute_reply.started": "2022-02-19T21:37:18.726533Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "# Plot the mel spectogram\n",
    "img = librosa.display.specshow(S_db_mel,\n",
    "                              x_axis='time',\n",
    "                              y_axis='log',\n",
    "                              ax=ax)\n",
    "ax.set_title('Mel Spectogram Example', fontsize=20)\n",
    "fig.colorbar(img, ax=ax, format=f'%0.2f')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation\n",
    "\n",
    "This code processes audio data from the UrbanSound8K dataset to prepare features and labels for a machine learning model. The key steps include:\n",
    "\n",
    "1. Feature Extraction:\n",
    "\n",
    "    Each WAV file is converted into a log Mel spectrogram using librosa, representing its frequency content.\n",
    "    Audio is standardized to 4 seconds by either truncating longer files or padding shorter ones by repeating the signal.\n",
    "\n",
    "2. Label Processing:\n",
    "\n",
    "    Labels are extracted from the filenames and converted into integers.\n",
    "    Labels are then one-hot encoded for compatibility with classification models.\n",
    "\n",
    "3. Data Saving:\n",
    "\n",
    "    Features and one-hot encoded labels are saved as .npy files for efficient loading and use in subsequent steps.\n",
    "\n",
    "4. Structure:\n",
    "\n",
    "    The process is applied to each fold of the UrbanSound8K dataset, and results are saved in a specified output directory.\n",
    "    This ensures the audio data is preprocessed and organized for easy integration into deep learning pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "from librosa.feature import melspectrogram\n",
    "\n",
    "def LOG_MEL_SPEC(parent_dir, sub_dir):\n",
    "    labels = []\n",
    "    log_mel_spectrogram = []\n",
    "    exten = \"*.wav\"\n",
    "    \n",
    "    for filename in glob.glob(os.path.join(parent_dir, sub_dir, exten)):\n",
    "        # Extract label from filename - assuming the class name is embedded in the filename\n",
    "        label = filename.split('fold')[1].split('-')[1]  # Adjust this as necessary for the filename format\n",
    "        labels.append(int(label))  # Convert label to integer\n",
    "        f, sr = librosa.load(filename, sr=16000)  # Load audio file with 16kHz sample rate\n",
    "        \n",
    "        # Define target duration (4 seconds)\n",
    "        four_sec_samples = 4 * sr\n",
    "        if len(f) >= four_sec_samples:\n",
    "            # Take first 4 seconds if the audio is long enough\n",
    "            log_mel_spec = librosa.power_to_db(\n",
    "                melspectrogram(y=f[:four_sec_samples], sr=sr, n_fft=1024, hop_length=128)\n",
    "            )\n",
    "        else:\n",
    "            # Pad audio to 4 seconds if it's shorter\n",
    "            while len(f) < four_sec_samples:\n",
    "                f = np.concatenate((f, f))  # Repeat audio to pad\n",
    "            log_mel_spec = librosa.power_to_db(\n",
    "                melspectrogram(y=f[:four_sec_samples], sr=sr, n_fft=1024, hop_length=128)\n",
    "            )\n",
    "        \n",
    "        log_mel_spectrogram.append(log_mel_spec)\n",
    "    \n",
    "    return np.array(log_mel_spectrogram), np.array(labels, dtype=int)\n",
    "\n",
    "def encode(labels):\n",
    "    # One hot encoding of labels\n",
    "    labels_total = len(labels)\n",
    "    unique_labels_total = len(np.unique(labels))\n",
    "    one_hot_encoded = np.zeros((labels_total, unique_labels_total))\n",
    "    one_hot_encoded[np.arange(labels_total), labels] = 1\n",
    "    return one_hot_encoded\n",
    "\n",
    "def file_creator(final_path, filename):\n",
    "    new_path = os.path.join(os.getcwd(), final_path)\n",
    "    if not os.path.exists(new_path):\n",
    "        os.makedirs(new_path)\n",
    "    return os.path.join(new_path, filename)\n",
    "\n",
    "# Set the parent directory where UrbanSound8K data is stored\n",
    "parent_directory = 'UrbanSound8K/audio'  # Adjust this path as needed\n",
    "final_dir = \"UrbanSound8K/UrbanSound8K_Processed\"\n",
    "\n",
    "# Process each fold and save the features and labels\n",
    "sub_dirs = ['fold1', 'fold2', 'fold3', 'fold4', 'fold5', 'fold6', 'fold7', 'fold8', 'fold9', 'fold10']\n",
    "\n",
    "for sub_dir in sub_dirs:\n",
    "    print(f\"Processing {sub_dir}...\")\n",
    "    features, labels = LOG_MEL_SPEC(parent_directory, sub_dir)\n",
    "    \n",
    "    # One hot encode the labels\n",
    "    labels_encoded = encode(labels)\n",
    "    \n",
    "    # Create filenames for saving features and labels\n",
    "    feature_file = file_creator(final_dir, f'{sub_dir}_features.npy')\n",
    "    labels_file = file_creator(final_dir, f'{sub_dir}_labels.npy')\n",
    "    \n",
    "    # Save the extracted features and labels\n",
    "    np.save(feature_file, features)\n",
    "    print(f\"Saved features for {sub_dir} at {feature_file}\")\n",
    "    np.save(labels_file, labels_encoded)\n",
    "    print(f\"Saved labels for {sub_dir} at {labels_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Fold Assignment and Data Preparation\n",
    "Assigns specific folds for training, validation, and testing, ensuring proper data splits. Also loads preprocessed features and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the features and labels for each fold\n",
    "processed_dir = 'UrbanSound8K/UrbanSound8K_Processed'\n",
    "\n",
    "# Specify folds\n",
    "folds = [f'fold{i}' for i in range(1, 11)]  # Folds 1 to 10\n",
    "\n",
    "# Assign test, validation, and training folds dynamically\n",
    "test_fold = folds[9]  # Use fold 8 for testing (index 7)\n",
    "validation_fold = folds[8]  # Use fold 9 for validation (index 8)\n",
    "train_folds = [fold for fold in folds if fold not in [test_fold, validation_fold]]  # Remaining for training\n",
    "\n",
    "# Debugging: Print the fold assignments\n",
    "print(f\"Training folds: {train_folds}\")\n",
    "print(f\"Validation fold: {validation_fold}\")\n",
    "print(f\"Test fold: {test_fold}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Data Loading Function\n",
    "Defines a function to load features and labels for specified folds and concatenates them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(folds, processed_dir):\n",
    "    features_list, labels_list = [], []\n",
    "    for fold in folds:\n",
    "        features_file = f\"{processed_dir}/{fold}_features.npy\"\n",
    "        labels_file = f\"{processed_dir}/{fold}_labels.npy\"\n",
    "        features_list.append(np.load(features_file))\n",
    "        labels_list.append(np.load(labels_file))\n",
    "    return np.concatenate(features_list), np.concatenate(labels_list)\n",
    "# Load training, validation, and test data\n",
    "X_train, y_train = load_data(train_folds, processed_dir)\n",
    "X_val, y_val = load_data([validation_fold], processed_dir)\n",
    "X_test, y_test = load_data([test_fold], processed_dir)\n",
    "\n",
    "# Reshape features for CNN input: (samples, height, width, channels)\n",
    "X_train = X_train[..., np.newaxis]\n",
    "X_val = X_val[..., np.newaxis]\n",
    "X_test = X_test[..., np.newaxis]\n",
    "\n",
    "# Ensure labels are one-hot encoded\n",
    "num_classes = 10\n",
    "y_train = np.reshape(y_train, (-1, num_classes))\n",
    "y_val = np.reshape(y_val, (-1, num_classes))\n",
    "y_test = np.reshape(y_test, (-1, num_classes))\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "print(f\"X_val shape: {X_val.shape}, y_val shape: {y_val.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. CNN Model Architecture\n",
    "Defines a sequential CNN model for classification, including convolutional layers, pooling, and dense layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "    layers.InputLayer(input_shape=(128, 251, 1)),  # Input shape matches your data\n",
    "    \n",
    "    # Example of convolutional layers with 'same' padding\n",
    "    layers.Conv2D(32, (3, 3), activation='tanh'),  # 'same' padding keeps dimensions\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),  # Pooling reduces dimensions\n",
    "\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),  # Pooling further reduces dimensions\n",
    "\n",
    "    # Example of a smaller pool size to prevent dimension collapse\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),  # More pooling layers\n",
    "\n",
    "    # Flatten and output layers\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(128,activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')  # Adjust to match the number of classes in your dataset\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Generating Noisy Examples\n",
    "Generates noisy data based on misclassified validation samples to augment the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_noisy_examples(X, y, model, noise_factor=0.1, ratio=0.05):\n",
    "    \"\"\"\n",
    "    Generate a limited number of noisy examples for misclassified samples.\n",
    "    Args:\n",
    "        X: Input validation data.\n",
    "        y: True labels for validation data.\n",
    "        model: Trained model for prediction.\n",
    "        noise_factor: The magnitude of noise to add.\n",
    "        ratio: Proportion of noisy samples to generate relative to misclassifications (e.g., 0.1 for 1:10).\n",
    "    Returns:\n",
    "        X_noisy: Generated noisy samples.\n",
    "        y_noisy: Corresponding labels for noisy samples.\n",
    "    \"\"\"\n",
    "    # Predict on the validation data\n",
    "    y_pred = model.predict(X)\n",
    "    y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "    y_true_labels = np.argmax(y, axis=1)\n",
    "    \n",
    "    # Identify misclassified samples\n",
    "    misclassified_indices = np.where(y_pred_labels != y_true_labels)[0]\n",
    "        # Determine the number of noisy samples to generate\n",
    "    num_noisy_samples = max(1, int(len(misclassified_indices) * ratio))  # At least 1 sample\n",
    "    print(f\"Total misclassified: {len(misclassified_indices)}, Ratio: {ratio}, Noisy samples to generate: {num_noisy_samples}\")\n",
    "\n",
    "    \n",
    "    # Determine the number of noisy samples to generate\n",
    "    num_noisy_samples = max(1, int(len(misclassified_indices) * ratio))  # At least 1 sample\n",
    "    selected_indices = np.random.choice(misclassified_indices, size=num_noisy_samples, replace=False)\n",
    "    \n",
    "    X_noisy = []\n",
    "    y_noisy = []\n",
    "    \n",
    "    for idx in selected_indices:\n",
    "        # Add Gaussian noise to the misclassified sample\n",
    "        noise = noise_factor * np.random.normal(size=X[idx].shape)\n",
    "        noisy_sample = np.clip(X[idx] + noise, 0, 1)  # Ensure values are within range\n",
    "        X_noisy.append(noisy_sample)\n",
    "        y_noisy.append(y[idx])  # Use the correct label\n",
    "    \n",
    "    return np.array(X_noisy), np.array(y_noisy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Training the Model\n",
    "Trains the model with early stopping, dynamically adds noisy examples, and saves the best weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n",
    "\n",
    "# Training with noisy examples between epochs\n",
    "\n",
    "history = []  # To store history across all epochs\n",
    "max_epochs = 50\n",
    "patience_limit = 6  # To check for manual early stopping (optional)\n",
    "\n",
    "# Initialize counters and flags\n",
    "early_stop_counter = 0\n",
    "best_val_loss = float('inf')  # Start with a very high value\n",
    "\n",
    "best_weights = None  # Initialize variable to store the best weights\n",
    "\n",
    "for epoch in range(1, max_epochs + 1):\n",
    "    print(f\"Epoch {epoch}/{max_epochs}\")\n",
    "\n",
    "    # Train model for one epoch\n",
    "    hist = model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        batch_size=64,\n",
    "        epochs=1,\n",
    "        validation_data=(X_val, y_val),\n",
    "        verbose=1,\n",
    "        callbacks=[early_stopping, reduce_lr]\n",
    "    )\n",
    "\n",
    "    # Store history\n",
    "    history.append(hist.history)\n",
    "\n",
    "    # Extract validation loss for manual early stopping check\n",
    "    val_loss = hist.history.get('val_loss', [None])[-1]\n",
    "    if val_loss is not None:\n",
    "        print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_weights = model.get_weights()  # Save best weights\n",
    "            early_stop_counter = 0  # Reset counter if there's improvement\n",
    "        else:\n",
    "            early_stop_counter += 1  # Increment counter if no improvement\n",
    "\n",
    "    # Check for early stopping (manual or callback-based)\n",
    "    if early_stop_counter >= patience_limit:\n",
    "        print(f\"Early stopping triggered after {epoch} epochs. Best val_loss: {best_val_loss:.4f}\")\n",
    "        model.set_weights(best_weights)  # Restore the best weights\n",
    "        break\n",
    "\n",
    "    # Generate noisy examples based on validation performance\n",
    "    X_noisy, y_noisy = generate_noisy_examples(X_val, y_val, model, noise_factor=0.05, ratio=0.05)\n",
    "\n",
    "    # Inject noisy examples back into training\n",
    "    if len(X_noisy) > 0:\n",
    "        X_train = np.concatenate([X_train, X_noisy])\n",
    "        y_train = np.concatenate([y_train, y_noisy])\n",
    "        print(f\"Added {len(X_noisy)} noisy examples to the training set.\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Model Evaluation\n",
    "Evaluates the model on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 107620,
     "sourceId": 256618,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30162,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
