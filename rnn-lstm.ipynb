{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import librosa\n",
    "import pickle\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Para guardar os dados em disco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pkl(data, path):\n",
    "    try:\n",
    "        with open(path, \"wb\") as saved_data:\n",
    "            pickle.dump(data, saved_data)\n",
    "    except:\n",
    "        print('Fail to save data')\n",
    "\n",
    "def load_pkl(path):\n",
    "    try:\n",
    "        with open(path, \"rb\") as loaded_data:\n",
    "            to_return = pickle.load(loaded_data)\n",
    "            return to_return\n",
    "    except:\n",
    "        print('Fail to load data')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slice_file_name</th>\n",
       "      <th>fsID</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>salience</th>\n",
       "      <th>fold</th>\n",
       "      <th>classID</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100032-3-0-0.wav</td>\n",
       "      <td>100032</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.317551</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>dog_bark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100263-2-0-117.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>58.5</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100263-2-0-121.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>60.5</td>\n",
       "      <td>64.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100263-2-0-126.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>63.0</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100263-2-0-137.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>68.5</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      slice_file_name    fsID  start        end  salience  fold  classID  \\\n",
       "0    100032-3-0-0.wav  100032    0.0   0.317551         1     5        3   \n",
       "1  100263-2-0-117.wav  100263   58.5  62.500000         1     5        2   \n",
       "2  100263-2-0-121.wav  100263   60.5  64.500000         1     5        2   \n",
       "3  100263-2-0-126.wav  100263   63.0  67.000000         1     5        2   \n",
       "4  100263-2-0-137.wav  100263   68.5  72.500000         1     5        2   \n",
       "\n",
       "              class  \n",
       "0          dog_bark  \n",
       "1  children_playing  \n",
       "2  children_playing  \n",
       "3  children_playing  \n",
       "4  children_playing  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../UrbanSound8K/metadata/UrbanSound8K.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "distribuição das classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['class'].value_counts().plot(kind='pie', autopct='%1.0f%%', figsize=(4,4))\n",
    "plt.title('Class Distribution')\n",
    "plt.ylabel('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feature extraction and pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Padding of the Audio to a Fixed Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def padding(path, duration = 4, sr = 22050, files_limit = -1, verbose = False):\n",
    "    files = librosa.util.find_files(path)\n",
    "    data = []\n",
    "\n",
    "    for index, file_path in enumerate(files):\n",
    "        if files_limit != -1 and index >= files_limit:\n",
    "            break\n",
    "        if verbose:\n",
    "            print(f\"Processing audio {index + 1}/{len(files)}\")\n",
    "        try:\n",
    "            audio, _ = librosa.load(file_path, sr=sr, mono=True)\n",
    "\n",
    "            audio = np.pad(audio, (0, max(0, duration*sr - len(audio))), mode='constant')\n",
    "            audio = audio[:duration * sr]\n",
    "\n",
    "            file_name = os.path.basename(file_path)\n",
    "            data.append([file_name, audio])\n",
    "        \n",
    "        except Exception:\n",
    "            print(f\"Error in processig file {file_path}: {Exception}\")\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(dataframe, audios, hop_length = 512, n_fft = 512):\n",
    "    log_spectograms = []\n",
    "    labels = []\n",
    "\n",
    "    for index in range(len(audios)):\n",
    "        try:\n",
    "            file_name =audios[index][0]\n",
    "            if file_name:\n",
    "                row = dataframe.loc[dataframe[\"slice_file_name\"] == file_name]\n",
    "\n",
    "                if not row.empty:\n",
    "                    label = row.iloc[0,6]\n",
    "                    spectogram = np.abs(librosa.core.stft(\n",
    "                        y = np.array(audios[index][1]),\n",
    "                        hop_length = hop_length,\n",
    "                        n_fft = n_fft\n",
    "                    ))\n",
    "                    log_spectogram = librosa.amplitude_to_db(spectogram)\n",
    "                    log_spectograms.append(log_spectogram)\n",
    "                    labels.append(label)\n",
    "        except Exception:\n",
    "            print(f\"Error in processig file {audios[index][0]}: {Exception}\")\n",
    "\n",
    "    log_spectograms = np.array(log_spectograms)\n",
    "    labels = np.array(labels)\n",
    "    return log_spectograms, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data normalization and pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_paths = [\"../UrbanSound8K/audio/fold1\",\n",
    "              \"../UrbanSound8K/audio/fold2\",\n",
    "              \"../UrbanSound8K/audio/fold3\",\n",
    "              \"../UrbanSound8K/audio/fold4\",\n",
    "              \"../UrbanSound8K/audio/fold5\",\n",
    "              \"../UrbanSound8K/audio/fold6\",\n",
    "              \"../UrbanSound8K/audio/fold7\",\n",
    "              \"../UrbanSound8K/audio/fold8\",\n",
    "              \"../UrbanSound8K/audio/fold9\",\n",
    "              \"../UrbanSound8K/audio/fold10\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Fold Number 1\n",
      "Features Shape:  (873, 173, 257)\n",
      "Labels Shape:  (873, 10) \n",
      "\n",
      "Processing Fold Number 2\n",
      "Features Shape:  (888, 173, 257)\n",
      "Labels Shape:  (888, 10) \n",
      "\n",
      "Processing Fold Number 3\n",
      "Features Shape:  (925, 173, 257)\n",
      "Labels Shape:  (925, 10) \n",
      "\n",
      "Processing Fold Number 4\n",
      "Features Shape:  (990, 173, 257)\n",
      "Labels Shape:  (990, 10) \n",
      "\n",
      "Processing Fold Number 5\n",
      "Features Shape:  (936, 173, 257)\n",
      "Labels Shape:  (936, 10) \n",
      "\n",
      "Processing Fold Number 6\n",
      "Features Shape:  (823, 173, 257)\n",
      "Labels Shape:  (823, 10) \n",
      "\n",
      "Processing Fold Number 7\n",
      "Features Shape:  (838, 173, 257)\n",
      "Labels Shape:  (838, 10) \n",
      "\n",
      "Processing Fold Number 8\n",
      "Features Shape:  (806, 173, 257)\n",
      "Labels Shape:  (806, 10) \n",
      "\n",
      "Processing Fold Number 9\n",
      "Features Shape:  (816, 173, 257)\n",
      "Labels Shape:  (816, 10) \n",
      "\n",
      "Processing Fold Number 10\n",
      "Features Shape:  (837, 173, 257)\n",
      "Labels Shape:  (837, 10) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "features = np.empty((10,), dtype=object)\n",
    "label = np.empty((10,), dtype=object)\n",
    "\n",
    "for i, fold in enumerate(fold_paths):\n",
    "    print(f\"Processing Fold Number {i+1}\")\n",
    "    audio_data = padding(fold)\n",
    "\n",
    "    log_spectograms, labels = feature_extraction(df, audio_data)\n",
    "    log_spectograms_normalized = (log_spectograms - np.mean(log_spectograms)) / np.std(log_spectograms)\n",
    "    log_spectograms_normalized = log_spectograms_normalized.transpose(0,2,1)\n",
    "    \n",
    "    encoded_labels = np.zeros((len(labels), 10))\n",
    "    encoded_labels[np.arange(len(labels)), labels] = 1\n",
    "    \n",
    "    features[i] = log_spectograms_normalized\n",
    "    label[i] = encoded_labels\n",
    "    print(\"Features Shape: \",features[i].shape)\n",
    "    print(\"Labels Shape: \",label[i].shape,\"\\n\")\n",
    "    \n",
    "    del log_spectograms\n",
    "    del log_spectograms_normalized\n",
    "    del encoded_labels\n",
    "    gc.collect() # libertar memoria\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Input Layer\n",
    "- Shape: (x, y) where:\n",
    "  - x is the number of timesteps (sequence length).\n",
    "  - y is the number of features per timestep (e.g., MFCC coefficients).\n",
    "- Purpose: The model expects a sequential input where each timestep represents a feature vector of the audio signal.\n",
    "#### 2. First Bidirectional LSTM Layer\n",
    "Description: A Bidirectional LSTM with 128 units.\n",
    "- Bidirectionality: Processes the sequence in both forward and backward directions to capture dependencies in the audio signal from past and future timesteps.\n",
    "- Activation: tanh for non-linearity.\n",
    "- Kernel Initialization: glorot_uniform for balanced weight initialization.\n",
    "- Output: Produces a sequence of 128 features for each timestep.\n",
    "- Dropout (0.3): <b>Randomly drops 30% of connections to prevent overfitting.</b>\n",
    "- Batch Normalization: <b>Normalizes the output of the LSTM layer, ensuring stability during training by keeping activations in a consistent range.</b>\n",
    "\n",
    "#### 3. Second Bidirectional LSTM Layer\n",
    "Description: Another Bidirectional LSTM with 128 units.\n",
    "- Purpose: Further refines temporal features extracted from the first LSTM layer, learning more complex patterns.\n",
    "- Output: Produces a sequence of 128 features for each timestep.\n",
    "- Dropout (0.3): <b>Again, drops 30% of connections for regularization.</b>\n",
    "- Batch Normalization: <b>Stabilizes activations and accelerates convergence.</b>\n",
    "\n",
    "#### 4. TimeDistributed Dense Layers\n",
    "Description: Fully connected layers applied independently to each timestep. These layers transform the feature representation at each timestep into higher-level abstractions.\n",
    "- First Dense Layer:\n",
    "  - Units: 128 neurons.\n",
    "  - Activation: ReLU for faster training and reduced vanishing gradient issues.\n",
    "  - Regularization: L2 regularization (0.01) to prevent overfitting.\n",
    "  - Dropout (0.2): Drops 20% of connections.\n",
    "- Second Dense Layer:\n",
    "  - Units: 64 neurons.\n",
    "  - Activation: ReLU.\n",
    "  - Regularization: L2 regularization (0.01).\n",
    "  - Dropout (0.2).\n",
    "  - Purpose: These layers learn high-level feature transformations for each timestep.\n",
    "\n",
    "#### 5. Flatten Layer\n",
    "Description: Flattens the outputs of the TimeDistributed Dense layers into a single vector.\n",
    "- Purpose: Converts the 2D sequence of features into a 1D vector suitable for final classification.\n",
    "\n",
    "#### 6. Output Layer\n",
    "Description: A fully connected Dense layer with 10 neurons.\n",
    "- Activation: Softmax, which outputs a probability distribution over the 10 sound classes.\n",
    "- Purpose: Final classification into one of the 10 categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras import Sequential, regularizers, layers\n",
    "# from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "# from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional, TimeDistributed, Flatten, BatchNormalization\n",
    "\n",
    "# def create_bidirectional_model(x, y):\n",
    "#     input_shape = (x, y)  # Shape of X_train sample\n",
    "\n",
    "#     model = Sequential()\n",
    "\n",
    "#     # First Bidirectional LSTM layer\n",
    "#     model.add(Bidirectional(LSTM(64, return_sequences=True, activation='tanh', kernel_initializer='glorot_uniform'), input_shape=input_shape))\n",
    "#     model.add(Dropout(0.5))\n",
    "#     model.add(BatchNormalization())\n",
    "\n",
    "#     # Second Bidirectional LSTM layer\n",
    "#     model.add(Bidirectional(LSTM(64, return_sequences=True, activation='tanh')))\n",
    "#     model.add(Dropout(0.5))\n",
    "#     model.add(BatchNormalization())\n",
    "\n",
    "#     # TimeDistributed Dense layers\n",
    "#     model.add(TimeDistributed(Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.01))))\n",
    "#     model.add(Dropout(0.3))\n",
    "#     model.add(TimeDistributed(Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.01))))\n",
    "#     model.add(Dropout(0.3))\n",
    "\n",
    "#     # Flatten layer\n",
    "#     model.add(Flatten())\n",
    "\n",
    "#     # Fully connected output layer\n",
    "#     model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "#     return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential, regularizers, layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional, TimeDistributed, Flatten, BatchNormalization, GlobalAveragePooling1D\n",
    "\n",
    "def create_model1(x, y):\n",
    "    input_shape = (x, y)  # Shape of X_train sample\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    # 2 LSTM Layers\n",
    "    model.add(LSTM(64, input_shape = input_shape, return_sequences=True, activation = 'tanh'))\n",
    "    #model.add(LSTM(128, return_sequences= True, activation = 'tanh'))\n",
    "    \n",
    "\n",
    "    # Dense and Dropout Layers\n",
    "    model.add(TimeDistributed(Dense(64, activation='tanh', kernel_regularizer=regularizers.l2(0.01))))\n",
    "    model.add(TimeDistributed(Dense(32, activation='tanh', kernel_regularizer=regularizers.l2(0.01))))\n",
    "    model.add(TimeDistributed(Dense(16, activation='tanh', kernel_regularizer=regularizers.l2(0.01))))\n",
    "    \n",
    "\n",
    "    # Flatten Layer\n",
    "    model.add(GlobalAveragePooling1D())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    \n",
    "\n",
    "    # Fully connected output layer\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Dense, TimeDistributed, GlobalAveragePooling1D\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "def create_model(x, y):\n",
    "    input_shape = (x, y)\n",
    "    model = Sequential()\n",
    "\n",
    "    # LSTM Layers with Dropout for regularization\n",
    "    model.add(LSTM(128, input_shape=input_shape, return_sequences=True, activation='tanh'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(LSTM(64, return_sequences=True, activation='tanh'))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    # TimeDistributed Dense Layers with Batch Normalization\n",
    "    model.add(TimeDistributed(Dense(64, activation='tanh', kernel_regularizer=regularizers.l2(0.001))))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(TimeDistributed(Dense(32, activation='tanh', kernel_regularizer=regularizers.l2(0.001))))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(TimeDistributed(Dense(16, activation='tanh', kernel_regularizer=regularizers.l2(0.001))))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(TimeDistributed(Dense(8, activation='tanh', kernel_regularizer=regularizers.l2(0.001))))\n",
    "    model.add(BatchNormalization())  # Stabilize training\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    # Pooling Layer\n",
    "    model.add(GlobalAveragePooling1D())\n",
    "\n",
    "    \n",
    "\n",
    "    # Output Layer\n",
    "    model.add(Dense(10, activation='softmax'))  # Assuming 10 classes\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\guica\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">173</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">197,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">173</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">173</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">173</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">173</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">173</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_1              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">173</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">173</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_2              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">173</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">173</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_3              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">173</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">173</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">173</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m173\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m197,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m173\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m173\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m49,408\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m173\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m173\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m173\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_1              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m173\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m173\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_2              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m173\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │           \u001b[38;5;34m528\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m173\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_3              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m173\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │           \u001b[38;5;34m136\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m173\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │            \u001b[38;5;34m32\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m173\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │            \u001b[38;5;34m90\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">254,066</span> (992.45 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m254,066\u001b[0m (992.45 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">254,050</span> (992.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m254,050\u001b[0m (992.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16</span> (64.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m16\u001b[0m (64.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#model = create_bidirectional_model(345, 513)\n",
    "model = create_model(173, 257)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "novo n2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "X_train Shape: (6919, 173, 257)\n",
      "y_train Shape: (6919, 10)\n",
      "X_test Shape: (888, 173, 257)\n",
      "y_test Shape: (888, 10)\n",
      "X_val Shape: (925, 173, 257)\n",
      "y_val Shape: (925, 10)\n",
      "Epoch 1/50\n",
      "\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 428ms/step - accuracy: 0.1708 - loss: 2.3824 - val_accuracy: 0.2605 - val_loss: 2.1542\n",
      "Epoch 2/50\n",
      "\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 389ms/step - accuracy: 0.2311 - loss: 2.2431 - val_accuracy: 0.2205 - val_loss: 2.1986\n",
      "Epoch 3/50\n",
      "\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 387ms/step - accuracy: 0.2450 - loss: 2.1537 - val_accuracy: 0.2627 - val_loss: 2.2533\n",
      "Epoch 4/50\n",
      "\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 388ms/step - accuracy: 0.2569 - loss: 2.0964 - val_accuracy: 0.2595 - val_loss: 2.2077\n",
      "Epoch 5/50\n",
      "\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 392ms/step - accuracy: 0.2750 - loss: 2.0558 - val_accuracy: 0.2454 - val_loss: 2.2789\n",
      "Epoch 6/50\n",
      "\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 390ms/step - accuracy: 0.2846 - loss: 2.0118 - val_accuracy: 0.2573 - val_loss: 2.1456\n",
      "Epoch 7/50\n",
      "\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 389ms/step - accuracy: 0.3160 - loss: 1.9620 - val_accuracy: 0.2508 - val_loss: 2.1626\n",
      "Epoch 8/50\n",
      "\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 410ms/step - accuracy: 0.3319 - loss: 1.9251 - val_accuracy: 0.2497 - val_loss: 2.1224\n",
      "Epoch 9/50\n",
      "\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 378ms/step - accuracy: 0.3418 - loss: 1.9123 - val_accuracy: 0.3189 - val_loss: 2.0898\n",
      "Epoch 10/50\n",
      "\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 370ms/step - accuracy: 0.3556 - loss: 1.8792 - val_accuracy: 0.2768 - val_loss: 2.0265\n",
      "Epoch 11/50\n",
      "\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 369ms/step - accuracy: 0.3576 - loss: 1.8530 - val_accuracy: 0.2832 - val_loss: 2.1021\n",
      "Epoch 12/50\n",
      "\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 373ms/step - accuracy: 0.3732 - loss: 1.8206 - val_accuracy: 0.2724 - val_loss: 2.1678\n",
      "Epoch 13/50\n",
      "\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 371ms/step - accuracy: 0.3860 - loss: 1.7890 - val_accuracy: 0.2984 - val_loss: 2.2793\n",
      "Epoch 14/50\n",
      "\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 371ms/step - accuracy: 0.3949 - loss: 1.7692 - val_accuracy: 0.2768 - val_loss: 2.2404\n",
      "Epoch 15/50\n",
      "\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 371ms/step - accuracy: 0.4043 - loss: 1.7478 - val_accuracy: 0.3005 - val_loss: 2.1718\n",
      "Epoch 16/50\n",
      "\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 376ms/step - accuracy: 0.4334 - loss: 1.7066 - val_accuracy: 0.2811 - val_loss: 2.4428\n",
      "Epoch 17/50\n",
      "\u001b[1m 84/217\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m50s\u001b[0m 379ms/step - accuracy: 0.4170 - loss: 1.7147"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[154], line 67\u001b[0m\n\u001b[0;32m     60\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[0;32m     61\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39moptimizer, \n\u001b[0;32m     62\u001b[0m     loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     63\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     64\u001b[0m )\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[1;32m---> 67\u001b[0m LSTM \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m     68\u001b[0m     X_train, y_train, \n\u001b[0;32m     69\u001b[0m     epochs\u001b[38;5;241m=\u001b[39mEPOCHS,\n\u001b[0;32m     70\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, \n\u001b[0;32m     71\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \n\u001b[0;32m     72\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39m(X_val, y_val),\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;66;03m#callbacks = early_stopping\u001b[39;00m\n\u001b[0;32m     74\u001b[0m )\n\u001b[0;32m     76\u001b[0m \u001b[38;5;66;03m# Predict unseen data\u001b[39;00m\n\u001b[0;32m     77\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32mc:\\Users\\guica\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\guica\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:320\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    319\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 320\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[0;32m    321\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32mc:\\Users\\guica\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\guica\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\guica\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    879\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[0;32m    880\u001b[0m )\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\guica\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\guica\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\guica\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\guica\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[0;32m    255\u001b[0m     )\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\guica\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1683\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1681\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1683\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m   1684\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1685\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   1686\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[0;32m   1687\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m   1688\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1689\u001b[0m   )\n\u001b[0;32m   1690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1691\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1692\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1693\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1697\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1698\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\guica\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "fold_metrics = []\n",
    "EPOCHS = 50\n",
    "fold = 0  # Current fold to be used as test set\n",
    "\n",
    "print(f\"Fold {fold+1}:\")\n",
    "\n",
    "# Initialize lists for train/test sets\n",
    "X_train, y_train = [], []\n",
    "X_test, y_test = None, None\n",
    "\n",
    "# Splitting the data into Train, Test, and Validation sets\n",
    "for i in range(10):\n",
    "    if i == 1:\n",
    "        # Set test data\n",
    "        X_test = features[i]\n",
    "        y_test = label[i]\n",
    "    elif i == 2:\n",
    "        # validation set\n",
    "        X_val = features[i]\n",
    "        y_val = label[i]\n",
    "        \n",
    "    else:\n",
    "        # Append data for training\n",
    "        if len(X_train) == 0:  # Initialize for the first fold\n",
    "            X_train = features[i]\n",
    "            y_train = label[i]\n",
    "        else:\n",
    "            X_train = np.concatenate((X_train, features[i]), axis=0)\n",
    "            y_train = np.concatenate((y_train, label[i]), axis=0)\n",
    "\n",
    "# Split test set into test and validation sets\n",
    "#X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=123)\n",
    "\n",
    "# Convert data to numpy arrays if not already\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "X_val = np.array(X_val)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "# Print set shapes\n",
    "print(f\"X_train Shape: {X_train.shape}\")\n",
    "print(f\"y_train Shape: {y_train.shape}\")\n",
    "print(f\"X_test Shape: {X_test.shape}\")\n",
    "print(f\"y_test Shape: {y_test.shape}\")\n",
    "print(f\"X_val Shape: {X_val.shape}\")\n",
    "print(f\"y_val Shape: {y_val.shape}\")\n",
    "\n",
    "#early_stopping = EarlyStopping(monitor = 'val_loss', patience = 5, restore_best_weights = True)\n",
    "#lr_scheduler = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.5, patience = 3, min_lr = 1e-4)\n",
    "\n",
    "# Compile model\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(\n",
    "    optimizer=optimizer, \n",
    "    loss='categorical_crossentropy', \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train model\n",
    "LSTM = model.fit(\n",
    "    X_train, y_train, \n",
    "    epochs=EPOCHS,\n",
    "    batch_size=32, \n",
    "    shuffle=False, \n",
    "    validation_data=(X_val, y_val),\n",
    "    #callbacks = early_stopping\n",
    ")\n",
    "\n",
    "# Predict unseen data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_reshape = np.argmax(y_pred, axis=1)\n",
    "y_test_reshape = np.argmax(y_test, axis=1)\n",
    "TestLoss, Testacc = model.evaluate(X_test, y_test)\n",
    "\n",
    "# Save fold results\n",
    "m_metrics = {\n",
    "    'loss': TestLoss, \n",
    "    'accuracy': Testacc, \n",
    "    'confusion_matrix': confusion_matrix(y_test_reshape, y_pred_reshape), \n",
    "    'history': model, \n",
    "    'history_dict': LSTM.history\n",
    "}\n",
    "\n",
    "fold_metrics.append(m_metrics)\n",
    "\n",
    "#model.save(f\"kfold_metrics_LSTM/model_fold{fold+1}.keras\", save_format=\"keras\")\n",
    "save_pkl(fold_metrics, f\"kfold_metrics_LSTM/metrics{fold+1}.pkl\")\n",
    "\n",
    "# Restart model to avoid memory leakage\n",
    "del model\n",
    "keras.backend.clear_session()\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### novo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "X_train Shape: (7859, 130, 513)\n",
      "y_train Shape: (7859, 10)\n",
      "X_test Shape: (436, 130, 513)\n",
      "y_test Shape: (436, 10)\n",
      "X_val Shape: (437, 130, 513)\n",
      "y_val Shape: (437, 10)\n",
      "Epoch 1/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 1s/step - accuracy: 0.1713 - loss: 5.3991 - val_accuracy: 0.3204 - val_loss: 3.8939\n",
      "Epoch 2/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 1s/step - accuracy: 0.2625 - loss: 3.7494 - val_accuracy: 0.2929 - val_loss: 3.2224\n",
      "Epoch 3/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 1s/step - accuracy: 0.2823 - loss: 3.1385 - val_accuracy: 0.3295 - val_loss: 2.7065\n",
      "Epoch 4/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 1s/step - accuracy: 0.3262 - loss: 2.6818 - val_accuracy: 0.3501 - val_loss: 2.4154\n",
      "Epoch 5/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 1s/step - accuracy: 0.3191 - loss: 2.4476 - val_accuracy: 0.3570 - val_loss: 2.2732\n",
      "Epoch 6/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 1s/step - accuracy: 0.3631 - loss: 2.1862 - val_accuracy: 0.3387 - val_loss: 2.0972\n",
      "Epoch 7/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 1s/step - accuracy: 0.3879 - loss: 2.0158 - val_accuracy: 0.4279 - val_loss: 1.9645\n",
      "Epoch 8/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 1s/step - accuracy: 0.4281 - loss: 1.8686 - val_accuracy: 0.4073 - val_loss: 1.9449\n",
      "Epoch 9/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 1s/step - accuracy: 0.4404 - loss: 1.7649 - val_accuracy: 0.3844 - val_loss: 2.0096\n",
      "Epoch 10/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 1s/step - accuracy: 0.4523 - loss: 1.6840 - val_accuracy: 0.3753 - val_loss: 2.1914\n",
      "Epoch 11/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 1s/step - accuracy: 0.4788 - loss: 1.5854 - val_accuracy: 0.4142 - val_loss: 1.8134\n",
      "Epoch 12/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 1s/step - accuracy: 0.5180 - loss: 1.4919 - val_accuracy: 0.4577 - val_loss: 1.8803\n",
      "Epoch 13/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 1s/step - accuracy: 0.5385 - loss: 1.4331 - val_accuracy: 0.3913 - val_loss: 1.9189\n",
      "Epoch 14/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 1s/step - accuracy: 0.5617 - loss: 1.3652 - val_accuracy: 0.4256 - val_loss: 1.8020\n",
      "Epoch 15/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 1s/step - accuracy: 0.5855 - loss: 1.3059 - val_accuracy: 0.4600 - val_loss: 1.7345\n",
      "Epoch 16/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 1s/step - accuracy: 0.5975 - loss: 1.2413 - val_accuracy: 0.3982 - val_loss: 1.9076\n",
      "Epoch 17/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 1s/step - accuracy: 0.6137 - loss: 1.2506 - val_accuracy: 0.4691 - val_loss: 2.0249\n",
      "Epoch 18/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 1s/step - accuracy: 0.6481 - loss: 1.1725 - val_accuracy: 0.4371 - val_loss: 1.9766\n",
      "Epoch 19/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 1s/step - accuracy: 0.6955 - loss: 1.0199 - val_accuracy: 0.3707 - val_loss: 2.5258\n",
      "Epoch 20/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 1s/step - accuracy: 0.6961 - loss: 1.0064 - val_accuracy: 0.4325 - val_loss: 2.0853\n",
      "Epoch 21/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 1s/step - accuracy: 0.7196 - loss: 0.9617 - val_accuracy: 0.4783 - val_loss: 1.8290\n",
      "Epoch 22/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 1s/step - accuracy: 0.7524 - loss: 0.8787 - val_accuracy: 0.4577 - val_loss: 2.3965\n",
      "Epoch 23/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 1s/step - accuracy: 0.7707 - loss: 0.8212 - val_accuracy: 0.4394 - val_loss: 2.7934\n",
      "Epoch 24/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 1s/step - accuracy: 0.7917 - loss: 0.7488 - val_accuracy: 0.4760 - val_loss: 2.4240\n",
      "Epoch 25/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 1s/step - accuracy: 0.8142 - loss: 0.6880 - val_accuracy: 0.4188 - val_loss: 2.7692\n",
      "Epoch 26/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 1s/step - accuracy: 0.8055 - loss: 0.7087 - val_accuracy: 0.4439 - val_loss: 2.2358\n",
      "Epoch 27/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 1s/step - accuracy: 0.7961 - loss: 0.7519 - val_accuracy: 0.4600 - val_loss: 2.2859\n",
      "Epoch 28/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 1s/step - accuracy: 0.8238 - loss: 0.6603 - val_accuracy: 0.4508 - val_loss: 2.1478\n",
      "Epoch 29/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 1s/step - accuracy: 0.8505 - loss: 0.6054 - val_accuracy: 0.4508 - val_loss: 2.2518\n",
      "Epoch 30/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 1s/step - accuracy: 0.8563 - loss: 0.5899 - val_accuracy: 0.4989 - val_loss: 2.3491\n",
      "Epoch 31/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 1s/step - accuracy: 0.8754 - loss: 0.5217 - val_accuracy: 0.4714 - val_loss: 2.8894\n",
      "Epoch 32/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 1s/step - accuracy: 0.8717 - loss: 0.5258 - val_accuracy: 0.4371 - val_loss: 3.9711\n",
      "Epoch 33/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 1s/step - accuracy: 0.8993 - loss: 0.4430 - val_accuracy: 0.4416 - val_loss: 2.8329\n",
      "Epoch 34/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 1s/step - accuracy: 0.9192 - loss: 0.3723 - val_accuracy: 0.4874 - val_loss: 3.7955\n",
      "Epoch 35/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 1s/step - accuracy: 0.9314 - loss: 0.3453 - val_accuracy: 0.4600 - val_loss: 3.4301\n",
      "Epoch 36/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 1s/step - accuracy: 0.9391 - loss: 0.3155 - val_accuracy: 0.4554 - val_loss: 3.4027\n",
      "Epoch 37/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 1s/step - accuracy: 0.9153 - loss: 0.3798 - val_accuracy: 0.4600 - val_loss: 3.0361\n",
      "Epoch 38/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 1s/step - accuracy: 0.8552 - loss: 0.5526 - val_accuracy: 0.4256 - val_loss: 3.0694\n",
      "Epoch 39/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 1s/step - accuracy: 0.8990 - loss: 0.4485 - val_accuracy: 0.4485 - val_loss: 3.0290\n",
      "Epoch 40/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 1s/step - accuracy: 0.9216 - loss: 0.3746 - val_accuracy: 0.4416 - val_loss: 3.7046\n",
      "Epoch 41/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1090s\u001b[0m 9s/step - accuracy: 0.9481 - loss: 0.2936 - val_accuracy: 0.4256 - val_loss: 3.9104\n",
      "Epoch 42/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 1s/step - accuracy: 0.9623 - loss: 0.2451 - val_accuracy: 0.4554 - val_loss: 3.1269\n",
      "Epoch 43/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 1s/step - accuracy: 0.9501 - loss: 0.2660 - val_accuracy: 0.5034 - val_loss: 2.8897\n",
      "Epoch 44/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 1s/step - accuracy: 0.9188 - loss: 0.4092 - val_accuracy: 0.4211 - val_loss: 3.5514\n",
      "Epoch 45/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 1s/step - accuracy: 0.9167 - loss: 0.3869 - val_accuracy: 0.5217 - val_loss: 3.3405\n",
      "Epoch 46/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 1s/step - accuracy: 0.9467 - loss: 0.2960 - val_accuracy: 0.4165 - val_loss: 3.6576\n",
      "Epoch 47/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 1s/step - accuracy: 0.9613 - loss: 0.2466 - val_accuracy: 0.4554 - val_loss: 3.4967\n",
      "Epoch 48/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 1s/step - accuracy: 0.9323 - loss: 0.3188 - val_accuracy: 0.4874 - val_loss: 3.7885\n",
      "Epoch 49/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 1s/step - accuracy: 0.9582 - loss: 0.2579 - val_accuracy: 0.4188 - val_loss: 4.1381\n",
      "Epoch 50/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 1s/step - accuracy: 0.9697 - loss: 0.2112 - val_accuracy: 0.4874 - val_loss: 3.8328\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 472ms/step\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 110ms/step - accuracy: 0.4398 - loss: 3.9125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'kfold_metrics_LSTM/model_fold1.keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 86\u001b[0m\n\u001b[0;32m     76\u001b[0m m_metrics \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m: TestLoss, \n\u001b[0;32m     78\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m: Testacc, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhistory_dict\u001b[39m\u001b[38;5;124m'\u001b[39m: LSTM\u001b[38;5;241m.\u001b[39mhistory\n\u001b[0;32m     82\u001b[0m }\n\u001b[0;32m     84\u001b[0m fold_metrics\u001b[38;5;241m.\u001b[39mappend(m_metrics)\n\u001b[1;32m---> 86\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkfold_metrics_LSTM/model_fold\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m, save_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     87\u001b[0m save_pkl(fold_metrics, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkfold_metrics_LSTM/metrics\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     89\u001b[0m \u001b[38;5;66;03m# Restart model to avoid memory leakage\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\guica\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\guica\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:141\u001b[0m, in \u001b[0;36msave_model\u001b[1;34m(model, filepath, weights_format, zipped)\u001b[0m\n\u001b[0;32m    139\u001b[0m         f\u001b[38;5;241m.\u001b[39mwrite(zip_filepath\u001b[38;5;241m.\u001b[39mgetvalue())\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 141\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filepath, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    142\u001b[0m         _save_model_to_fileobj(model, f, weights_format)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'kfold_metrics_LSTM/model_fold1.keras'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "fold_metrics = []\n",
    "EPOCHS = 50\n",
    "fold = 0  # Current fold to be used as test set\n",
    "\n",
    "print(f\"Fold {fold+1}:\")\n",
    "\n",
    "# Initialize lists for train/test sets\n",
    "X_train, y_train = [], []\n",
    "X_test, y_test = None, None\n",
    "\n",
    "# Splitting the data into Train, Test, and Validation sets\n",
    "for i in range(10):\n",
    "    if i == 0:\n",
    "        # Set test data\n",
    "        X_test = features[i]\n",
    "        y_test = label[i]\n",
    "    elif i == 1:\n",
    "        # validation set\n",
    "        X_val = features[i]\n",
    "        y_val = label[i]\n",
    "        \n",
    "    else:\n",
    "        # Append data for training\n",
    "        if len(X_train) == 0:  # Initialize for the first fold\n",
    "            X_train = features[i]\n",
    "            y_train = label[i]\n",
    "        else:\n",
    "            X_train = np.concatenate((X_train, features[i]), axis=0)\n",
    "            y_train = np.concatenate((y_train, label[i]), axis=0)\n",
    "\n",
    "# Split test set into test and validation sets\n",
    "#X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=123)\n",
    "\n",
    "# Convert data to numpy arrays if not already\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "X_val = np.array(X_val)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "# Print set shapes\n",
    "print(f\"X_train Shape: {X_train.shape}\")\n",
    "print(f\"y_train Shape: {y_train.shape}\")\n",
    "print(f\"X_test Shape: {X_test.shape}\")\n",
    "print(f\"y_test Shape: {y_test.shape}\")\n",
    "print(f\"X_val Shape: {X_val.shape}\")\n",
    "print(f\"y_val Shape: {y_val.shape}\")\n",
    "\n",
    "\n",
    "\n",
    "# Compile model\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(\n",
    "    optimizer=optimizer, \n",
    "    loss='categorical_crossentropy', \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train model\n",
    "LSTM = model.fit(\n",
    "    X_train, y_train, \n",
    "    epochs=EPOCHS,\n",
    "    batch_size=32, \n",
    "    shuffle=False, \n",
    "    validation_data=(X_val, y_val),\n",
    "   \n",
    ")\n",
    "\n",
    "# Predict unseen data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_reshape = np.argmax(y_pred, axis=1)\n",
    "y_test_reshape = np.argmax(y_test, axis=1)\n",
    "TestLoss, Testacc = model.evaluate(X_test, y_test)\n",
    "\n",
    "# Save fold results\n",
    "m_metrics = {\n",
    "    'loss': TestLoss, \n",
    "    'accuracy': Testacc, \n",
    "    'confusion_matrix': confusion_matrix(y_test_reshape, y_pred_reshape), \n",
    "    'history': model, \n",
    "    'history_dict': LSTM.history\n",
    "}\n",
    "\n",
    "fold_metrics.append(m_metrics)\n",
    "\n",
    "model.save(f\"kfold_metrics_LSTM/model_fold{fold+1}.keras\", save_format=\"keras\")\n",
    "save_pkl(fold_metrics, f\"kfold_metrics_LSTM/metrics{fold+1}.pkl\")\n",
    "\n",
    "# Restart model to avoid memory leakage\n",
    "del model\n",
    "keras.backend.clear_session()\n",
    "\n",
    "print(\"Done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (50,) and (24,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[78], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m val_loss_values \u001b[38;5;241m=\u001b[39m history_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     11\u001b[0m val_acc_values \u001b[38;5;241m=\u001b[39m history_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 13\u001b[0m ax[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mplot(epochs,loss_values,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mco\u001b[39m\u001b[38;5;124m'\u001b[39m,label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining Loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     14\u001b[0m ax[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mplot(epochs,val_loss_values,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation Loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     15\u001b[0m ax[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mset_title(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining and validation loss on fold \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m of 10\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\guica\\anaconda3\\Lib\\site-packages\\matplotlib\\axes\\_axes.py:1721\u001b[0m, in \u001b[0;36mAxes.plot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1478\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1479\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[0;32m   1480\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1718\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[0;32m   1719\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1720\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[1;32m-> 1721\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[0;32m   1722\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[0;32m   1723\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[1;32mc:\\Users\\guica\\anaconda3\\Lib\\site-packages\\matplotlib\\axes\\_base.py:303\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[1;34m(self, axes, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    301\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    302\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m--> 303\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_plot_args(\n\u001b[0;32m    304\u001b[0m     axes, this, kwargs, ambiguous_fmt_datakey\u001b[38;5;241m=\u001b[39mambiguous_fmt_datakey)\n",
      "File \u001b[1;32mc:\\Users\\guica\\anaconda3\\Lib\\site-packages\\matplotlib\\axes\\_base.py:499\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[1;34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[0;32m    496\u001b[0m     axes\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39mupdate_units(y)\n\u001b[0;32m    498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m--> 499\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must have same first dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    500\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    501\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y can be no greater than 2D, but have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    503\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (50,) and (24,)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = range(1, EPOCHS + 1)\n",
    "\n",
    "fig, ax = plt.subplots(len(fold_metrics), 2, figsize=(10, 5*len(fold_metrics)))\n",
    "\n",
    "\n",
    "for i in range(0,len(fold_metrics)):\n",
    "    history_dict = fold_metrics[i].get('history_dict')\n",
    "    loss_values=history_dict['loss']\n",
    "    acc_values=history_dict['accuracy']\n",
    "    val_loss_values = history_dict['val_loss']\n",
    "    val_acc_values = history_dict['val_accuracy']\n",
    "\n",
    "    ax[0].plot(epochs,loss_values,'co',label='Training Loss')\n",
    "    ax[0].plot(epochs,val_loss_values,'m', label='Validation Loss')\n",
    "    ax[0].set_title('Training and validation loss on fold '+str(i+1)+' of 10')\n",
    "    ax[0].set_xlabel('Epochs')\n",
    "    ax[0].set_ylabel('Loss')\n",
    "    ax[0].legend()\n",
    "\n",
    "    ax[1].plot(epochs,acc_values,'co', label='Training accuracy')\n",
    "    ax[1].plot(epochs,val_acc_values,'m', label='Validation accuracy')\n",
    "    ax[1].set_title('Training and validation accuracy on fold '+str(i+1)+' of 10')\n",
    "    ax[1].set_xlabel('Epochs')\n",
    "    ax[1].set_ylabel('Accuracy')\n",
    "    ax[1].legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### antigo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import keras\n",
    "fold_metrics = []\n",
    "EPOCHS = 50\n",
    "fold = 0\n",
    "\n",
    "f = \"fold\" + str(fold+1)\n",
    "print(\"Fold \"+str(fold+1)+\":\")\n",
    "\n",
    "X_train, y_train = [], []\n",
    "X_test, y_test = [], []\n",
    "    \n",
    "# Splitting the data into Test, Validation and Training sets\n",
    "for i in range(10):\n",
    "    if( i != fold):\n",
    "        X_train += features[i].tolist()\n",
    "        y_train.extend(label[i])\n",
    "        \n",
    "    else:\n",
    "        X_test = features[i]\n",
    "        y_test = labels[i]\n",
    "\n",
    "    \n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "        \n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size = 0.5, random_state = 123)\n",
    "\n",
    "# Print sets shapes\n",
    "print(f\"X_train Shape: {X_train.shape}\")\n",
    "print(f\"X_test Shape: {X_test.shape}\")\n",
    "print(f\"X_val Shape: {X_val.shape}\")\n",
    "\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate = 0.001)\n",
    "model.compile(\n",
    "    optimizer = optimizer, \n",
    "    loss = 'categorical_crossentropy', \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train model\n",
    "LSTM = model.fit(\n",
    "    X_train, y_train, \n",
    "    epochs = EPOCHS,\n",
    "    batch_size = 64, \n",
    "    shuffle = False, \n",
    "    validation_data=(X_val, y_val)\n",
    ")\n",
    "\n",
    "# Predict unseen data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "y_pred_reshape = np.argmax(y_pred, axis=1)\n",
    "y_test_reshape = np.argmax(y_test, axis=1)\n",
    "TestLoss, Testacc = model.evaluate(X_test, y_test)\n",
    "\n",
    "# Save fold results\n",
    "m_metrics = {\n",
    "    'loss': TestLoss, \n",
    "    'accuracy': Testacc, \n",
    "    'confusion_matrix': confusion_matrix(y_test_reshape, y_pred_reshape), \n",
    "    'history': model, 'history_dict': LSTM.history\n",
    "}\n",
    "\n",
    "fold_metrics.append(m_metrics)\n",
    "\n",
    "model.save(f\"kfold_metrics_LSTM/model_fold{fold+1}.keras\", save_format=\"keras\")\n",
    "save_pkl(fold_metrics, f\"kfold_metrics_LSTM/metrics{fold+1}.pkl\")\n",
    "\n",
    "# restart model to avoid memory leakage\n",
    "del model \n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "performance evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
